![Automoy Platform Logo](https://cloud.innovatingsustainabletechnology.com/apps/files_sharing/publicpreview/SL7ayF37TPessQT?file=/\&fileId=317\&x=3840\&y=2160\&a=true\&etag=4a4d71d889fe7f610d7c18700daf40f5)

# Automoy V2

**Automoy** is a modular, GPU-accelerated autonomous agent framework that blends LLM reasoning, visual parsing, and real-world OS-level control.

Originally based on [Self-Operating Computer by OthersideAI](https://github.com/OthersideAI/self-operating-computer), Automoy has evolved into a full-stack, pluggable system capable of UI automation, screen parsing, and soon, robotics.

> **Automoy turns screenshots and objectives into action.**

---

## ‚ú® What's New in V2?

* Full **GPU acceleration** for OCR and computer vision tasks
* **OmniParser**-based UI analysis
* Modular support for **LLMs** like Deepseek, Ollama, GPT-4, Mistral
* **Web UI (God Mode)** for real-time monitoring, task queue, and execution feedback
* Structured **plugin and script support**
* **Installer for one-click setup** on Windows

---

## üß† Project Overview

```
automoy-v2/
‚îú‚îÄ‚îÄ config/               # Config loader and runtime config.txt/py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ config.txt
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Entrypoint
‚îÇ   ‚îú‚îÄ‚îÄ operate.py        # Main Automoy execution logic
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py        # Prompt crafting
‚îÇ   ‚îú‚îÄ‚îÄ lm_interface.py   # Core LLM interface (used in legacy and current modules)
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py     # Custom exception handling
‚îÇ   ‚îú‚îÄ‚îÄ lm_interfaces/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main_interface.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ handlers/     # LLM input/output formatters
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ omniparser/   # OmniParser interface and sample output
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ operating_system/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ os_interface.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ region/       # Region mapping and coordinate translation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mapper.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ area_selector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vmware/       # VMWare controller interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_scraping/ # Scraping and HTML UI parsing
‚îÇ
‚îú‚îÄ‚îÄ dependencies/
‚îÇ   ‚îî‚îÄ‚îÄ OmniParser-master/ # OmniParser engine directory
‚îÇ
‚îú‚îÄ‚îÄ evaluations/          # Benchmarking + test scripts
‚îÇ
‚îú‚îÄ‚îÄ gui/
‚îÇ   ‚îú‚îÄ‚îÄ gui.py            # FastAPI frontend + control panel
‚îÇ   ‚îú‚îÄ‚îÄ static/           # Web assets (JS, CSS)
‚îÇ   ‚îî‚îÄ‚îÄ templates/        # HTML templates
‚îÇ
‚îú‚îÄ‚îÄ installer/
‚îÇ   ‚îú‚îÄ‚îÄ setup.py          # Launch installer
‚îÇ   ‚îú‚îÄ‚îÄ conda_setup.py
‚îÇ   ‚îú‚îÄ‚îÄ cuda_setup.py
‚îÇ   ‚îú‚îÄ‚îÄ omniparser_setup.py
‚îÇ   ‚îú‚îÄ‚îÄ vmware_setup.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ downloads/
‚îÇ   ‚îî‚îÄ‚îÄ aria2c.exe        # Download utility
‚îÇ
‚îú‚îÄ‚îÄ scripts/              # Custom automation routines
‚îú‚îÄ‚îÄ README.md
```

---

## ü§ñ How Automoy Works

1. **Screenshot Taken** (manually or on loop)
2. **OmniParser parses UI elements** from image
3. **LLM interprets context and decides next step**
4. **Automoy acts** (mouse clicks, keyboard input, etc.)

> Automoy "sees" the desktop, "thinks" about what to do, and then "acts" on the system directly.

---

## üìÖ System Requirements

### Minimum:

* 2GB VRAM GPU
* 8GB RAM
* CUDA 11.8+

### Recommended:

* 16GB RAM
* RTX-class GPU (3060+)

> Automoy requires **CUDA** to accelerate visual tasks. If CUDA is misconfigured, Automoy will not launch.

### OS Support:

* **Windows 10+ (official)**
* **Linux**: community support coming soon
* **macOS**: Not supported

---

## üõ†Ô∏è AMD GPU Support (Experimental)

CUDA is NVIDIA-exclusive, but the following projects offer possible AMD compatibility:

* [SCALE Toolkit](https://wccftech.com/nvidia-cuda-directly-run-on-amd-gpus-using-scale-toolkit/) ‚Äì CUDA-on-AMD translation layer
* [ZLUDA](https://www.xda-developers.com/nvidia-cuda-amd-zluda/) ‚Äì Converts CUDA binaries to Intel/AMD-compatible code

These are **not officially supported**, but adventurous users may test and report results.

---

## üöÄ Roadmap

* [IN-P] Web-based control panel (God Mode)
* [IN-P] Script/plugin loader with hot-reload capability
* [x] CUDA installer w/ PyTorch verification for GPU acceleration
* [ ] Multi-screen support for wider operational contexts
* [ ] OCR fallback pipeline to support CPU-only environments
* [ ] Real-time frame analysis loop (stream-based parsing for dynamic UI)
* [ ] OpenCL + integrated graphics support (non-CUDA fallback and broader hardware support)
* [ ] Portable Automoy OS under `os/` (USB-bootable image for appliance deployment)
* [ ] MOE (Mixture of Experts) agent logic and critical reasoning support
* [ ] Advanced geometric reasoning and spatial awareness via vision model extensions
* [ ] NVIDIA Isaac Sim integration (robotics interfaces modularized under `utils/`)
* [ ] Circuit simulator integration for electrical prototyping (e.g. Falstad, ngspice)
* [ ] Support for additional simulation tools (physics, CAD, electronics, or virtual environments)
* [ ] Adaptive manufacturing mode: Automoy as an orchestrator of physical/digital manufacturing workflows (via robotic arm + sensors)

---

## üîß Installation

1. Clone the repo
2. Navigate to `/installer`
3. Run `setup.py` or use `aria2c.exe` to fetch dependencies
4. Launch `main.py` from `core/`

---

## ‚ú® Bonus: Touchscreen + RGB Support (Optional)

Automoy can be deployed in custom hardware:

* Touchscreens (5"‚Äì7" HDMI + USB)
* RGB lighting (WS2812 via ESP32 or Arduino)
* 3D-printed cases for standalone or rack-mounted setups

This makes Automoy a physical, interactive AI agent appliance.

---

## üìö License & Acknowledgments

* Based on original ideas from OthersideAI
* OmniParser integration by Microsoft
* Inspired by the vision of local-first, agentic computing

**Built by Technologies-AI**
